##vllm installations--------------------------------------------------
# Install vLLM with CUDA 11.8.
export VLLM_VERSION=0.6.1.post1
export PYTHON_VERSION=310
pip install https://github.com/vllm-project/vllm/releases/download/v${VLLM_VERSION}/vllm-${VLLM_VERSION}+cu118-cp${PYTHON_VERSION}-cp${PYTHON_VERSION}-manylinux1_x86_64.whl --extra-index-url https://download.pytorch.org/whl/cu118
pip install vllm[torch] --extra-index-url https://download.pytorch.org/whl/cu118

##-------------------
 apt update
 apt install build-essential -y

-------------------------
apt install clang -y

------------------------
export WANDB_API_KEY=<your_api_key>
wandb login

-----------------------------
huggingface login cli